{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vangdale-krishna/forage-jpmc-swe-task-1/blob/main/CourseWork_Task_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYPIWDqhgGb-",
        "outputId": "ab9b21f0-f460-42c6-d02d-e41aa845d277"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=eac58a804cd73d02684de6295cfe031b45b1f29e4a325bdf83a2b262970d1677\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "# Install PySpark in Colab\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Import required libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import regexp_extract, col, count, sum, rank, lag, when, isnull\n",
        "\n",
        "# Create a Spark session\n",
        "spark = SparkSession.builder.appName(\"WebLogParser\").getOrCreate()\n",
        "\n",
        "# Read the web.log file\n",
        "weblog_file_data = spark.read.text(\"/content/drive/MyDrive/web.log\")\n",
        "\n",
        "# Define the regular expression pattern for CLF\n",
        "clf_pattern = r'^(\\S+) - - (\\S+) \"(\\S+) (\\S+) (\\S+)\" (\\d{3}) (\\d+) (.+)$'\n",
        "\n",
        "# Use the regular expression to extract fields into columns\n",
        "web_log_df = weblog_file_data.select(\n",
        "    regexp_extract(\"value\", clf_pattern, 1).alias(\"Host making the request\"),\n",
        "    regexp_extract(\"value\", clf_pattern, 2).alias(\"Timestamp\"),\n",
        "    regexp_extract(\"value\", clf_pattern, 3).alias(\"HTTP Method\"),\n",
        "    regexp_extract(\"value\", clf_pattern, 4).alias(\"URL\"),\n",
        "    regexp_extract(\"value\", clf_pattern, 5).alias(\"HTTP Version\"),\n",
        "    regexp_extract(\"value\", clf_pattern, 6).alias(\"HTTP Status Code\"),\n",
        "    regexp_extract(\"value\", clf_pattern, 7).cast(\"integer\").alias(\"Bytes in the reply\"),\n",
        "    regexp_extract(\"value\", clf_pattern, 8).alias(\"Message\"),\n",
        ")\n",
        "\n",
        "# Show the DataFrame\n",
        "web_log_df.show(20, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "A86p9Y0IiNCU",
        "outputId": "2cbd6f78-9de6-4e6c-a5fe-012765996114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-ca66f617f651>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Read the web.log file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mweblog_file_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/web.log\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Define the regular expression pattern for CLF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mtext\u001b[0;34m(self, paths, wholetext, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter)\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m     def csv(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: file:/content/drive/MyDrive/web.log."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Advanced query operations 1 - Trial\n",
        "# Grouping by \"HTTP Method\"\n",
        "# Aggregating the count of requests, sum of bytes, and calculating average bytes per request\n",
        "\n",
        "# advanced_query_result = web_log_df.groupBy(\"HTTP Method\").agg(\n",
        "#     count(\"HTTP Method\").alias(\"Request Count\"),\n",
        "#     sum(\"Bytes in the reply\").alias(\"Total Bytes\"),\n",
        "#     (sum(col(\"Bytes in the reply\")) / count(\"HTTP Method\")).alias(\"Average Bytes\")\n",
        "# )\n",
        "# advanced_query_result.show(truncate=False)"
      ],
      "metadata": {
        "id": "hWC_yIgu3tTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vrajraj Task 1 - Advanced query operations 1\n",
        "# In this advanced query:\n",
        "# To Understand the pattern and performance of the web service.\n",
        "# I filtered out successful requests with status codes which are equal to 200.\n",
        "# I grouped the data by \"Method\" and \"URL\".\n",
        "# I aggregated the count of requests, sum of bytes, and calculated average bytes per request.\n",
        "# I sorted the result by the number of requests in descending order.\n",
        "advanced_query_result = (\n",
        "    web_log_df\n",
        "    .filter((col(\"HTTP Status Code\") == 200))  # Filter successful requests\n",
        "    .groupBy(\"HTTP Method\", \"URL\")\n",
        "    .agg(\n",
        "        count(\"*\").alias(\"Request_Count\"),\n",
        "        sum(\"Bytes in the reply\").alias(\"Total_Bytes\"),\n",
        "        (sum(col(\"Bytes in the reply\")) / count(\"*\")).alias(\"Average_Bytes\"),\n",
        "    )\n",
        "    .orderBy(\"Request_Count\", ascending=False)\n",
        ")\n",
        "# Show the advanced query result\n",
        "advanced_query_result.show(20,truncate=False)"
      ],
      "metadata": {
        "id": "v3g5H8bvG9fK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Vrajraj Task 1 - Advanced Query 2\n",
        "# Calculates the cumulative sum of bytes within each \"HTTP Status Code\" partition.\n",
        "# Retrieves the lagged value of the \"Bytes in the reply\" column for each request within the \"HTTP Status Code\" partition.\n",
        "# This query provides information about the rank of each request within its partition, the cumulative sum of bytes up to that point,\n",
        "# and the previous value of bytes for each request.\n",
        "\n",
        "# windowSpec = Window.partitionBy(\"HTTP Status Code\").orderBy(\"Timestamp\")\n",
        "# advanced_query_two_2398922 = (\n",
        "#     web_log_df\n",
        "#     .withColumn(\"Cumulative_Sum_Bytes\", sum(\"Bytes in the reply\").over(windowSpec))\n",
        "#     .withColumn(\"Previous_Bytes\", lag(\"Bytes in the reply\").over(windowSpec))\n",
        "#     .select(\n",
        "#         \"HTTP Status Code\",\n",
        "#         \"Bytes in the reply\",\n",
        "#         \"Timestamp\",\n",
        "#         \"Cumulative_Sum_Bytes\",\n",
        "#         \"Previous_Bytes\"\n",
        "#     )\n",
        "# )\n",
        "# advanced_query_two_2398922.show(truncate=False)\n",
        "\n",
        "\n",
        "# Define the window specification\n",
        "windowSpec = Window.partitionBy(\"HTTP Status Code\").orderBy(\"Timestamp\")\n",
        "\n",
        "# Define the subquery for calculating percentage change\n",
        "percentage_change_subquery = (\n",
        "    col(\"Bytes in the reply\") - lag(\"Bytes in the reply\").over(windowSpec)\n",
        ") / lag(\"Bytes in the reply\").over(windowSpec) * 100\n",
        "\n",
        "# Main query with subquery\n",
        "advanced_query_with_subquery = (\n",
        "    web_log_df\n",
        "    .withColumn(\"Cumulative_Sum_Bytes\", sum(\"Bytes in the reply\").over(windowSpec))\n",
        "    .withColumn(\"Previous_Bytes\", lag(\"Bytes in the reply\").over(windowSpec))\n",
        "    .withColumn(\"Percentage_Change\", when(isnull(percentage_change_subquery), 0).otherwise(percentage_change_subquery))\n",
        "    .select(\n",
        "        \"HTTP Status Code\",\n",
        "        \"Bytes in the reply\",\n",
        "        \"Timestamp\",\n",
        "        \"Cumulative_Sum_Bytes\",\n",
        "        \"Previous_Bytes\",\n",
        "        \"Percentage_Change\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Show the result\n",
        "advanced_query_with_subquery.show(truncate=False)"
      ],
      "metadata": {
        "id": "EUdbsA6cjEfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SAI KRISHNA VANGDALE TASK-1 PRACTICE QUESTION :\n",
        "\n",
        "#the purpose of this code is to calculate both the average bytes and the cumulative average bytes for each HTTP Method\n",
        "# Defining a window specification based on HTTP Method and Timestamp columns\n",
        "# Calculating the average Bytes in the reply for each HTTP Method\n",
        "# Calculating cumulative average Bytes in the reply for each HTTP Method\n",
        "# and average Bytes in the reply for each HTTP Method\n",
        "# Calculate cumulative average Bytes in the reply for each HTTP Method\n",
        "# Show the result for average Bytes in the reply for each HTTP Method\n",
        "# Show the result for cumulative average Bytes in the reply for each HTTP Method\n",
        "\n",
        "# window_spec = Window.partitionBy(\"HTTP Method\").orderBy(\"Timestamp\")\n",
        "# avg_bytes_df = web_log_df.withColumn(\n",
        "#    \"Average_Bytes\",\n",
        "#   avg(\"Bytes in the reply\").over(window_spec)\n",
        "# )\n",
        "# cum_avg_bytes_df = web_log_df.withColumn(\n",
        "#    \"Cumulative_Avg_Bytes\",\n",
        "#   avg(\"Bytes in the reply\").over(window_spec.rowsBetween(Window.unboundedPreceding, 0))\n",
        "# )\n",
        "\n",
        "# avg_bytes_by_method_df = avg_bytes_df.groupBy(\"HTTP Method\").agg(\n",
        "#    avg(\"Average_Bytes\").alias(\"Average_Bytes\")\n",
        "# )\n",
        "# cum_avg_bytes_by_method_df = cum_avg_bytes_df.groupBy(\"HTTP Method\").agg(\n",
        "#    avg(\"Cumulative_Avg_Bytes\").alias(\"Cumulative_Avg_Bytes\")\n",
        "# )\n",
        "# avg_bytes_by_method_df.show(truncate=False)\n",
        "# cum_avg_bytes_by_method_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "xW_kkB2_-gNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SAI KRISHNA VANGDALE TASK-1 / QUERY- 1:\n",
        "#This query is for ranking rows based on the amount of data \"Bytes in the reply\" within each HTTP method\n",
        "# and  calculating the running total of bytes for each row within its HTTP method partition.\n",
        "#This query helps to gain insights into the distribution and accumulation of the data over time and across different HTTP methods.\n",
        "\n",
        "#I have added rank function to each row within its HTTP method\n",
        "#I have partitioned the rank func by \"HTTP METHOD\" and\n",
        "#sorted the ordered by \"Bytes in the reply\" in descending order.\n",
        "#computed the \"Running_Total_Bytes\",with sum of  \"Bytes in the reply\"   for each row within its \"HTTP Method\" partition, ordered by \"Timestamp.\"\n",
        "\n",
        "# Defining the rank window specification\n",
        "\n",
        "rank_window_spec = Window.partitionBy(\"HTTP Method\").orderBy(desc(\"Bytes in the reply\"))\n",
        "ranked_rows_df = web_log_df.withColumn(\n",
        "    \"Rank\",\n",
        "    rank().over(rank_window_spec)\n",
        ")\n",
        "running_total_df = web_log_df.withColumn(\n",
        "    \"Running_Total_Bytes\",\n",
        "    sum(\"Bytes in the reply\").over(Window.partitionBy(\"HTTP Method\").orderBy(\"Timestamp\").rowsBetween(Window.unboundedPreceding, 0))\n",
        ")\n",
        "\n",
        "# Main query with subqueries\n",
        "complex_query_df = (\n",
        "    web_log_df\n",
        "    .select(\n",
        "\n",
        "        \"Timestamp\",\n",
        "        \"HTTP Method\",\n",
        "        \"Bytes in the reply\",\n",
        "        rank().over(rank_window_spec).alias(\"Rank\"),\n",
        "        sum(\"Bytes in the reply\").over(Window.partitionBy(\"HTTP Method\").orderBy(\"Timestamp\").rowsBetween(Window.unboundedPreceding, 0)).alias(\"Running_Total_Bytes\")\n",
        "    )\n",
        ")\n",
        "\n",
        "# Show the result\n",
        "complex_query_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "Bi-UTU6Vt7S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SAI KRISHNA VANGDALE TASK -1 / QUERY 2:\n",
        "#This query is to find the average no. of bytes for each \"HTTP Method\" and the percentage of entries in each HTTP method group where the \"Bytes in the reply\" is above the calculated average.\n",
        "\n",
        "#In this query i have first created a window specification where the data is partitioned by \"\" HTTP method\".\n",
        "#The window  function will operate independently for each  unique \"HTTP method\".\n",
        "#I calculated the average value of \"Bytes in the reply\" for each row within its respective HTTP method group.\n",
        "#Next i have calculated the percentage of rows in each HTTP method group where the \"Bytes in the reply\" is greater than the calculated average.\n",
        "#aggregated with the sum and count functions to determine the percentage .\n",
        "\n",
        "window_spec = Window.partitionBy(\"HTTP Method\")\n",
        "\n",
        "# Calculate the average bytes for each HTTP method\n",
        "avg_bytes_df = (\n",
        "    web_log_df\n",
        "    .withColumn(\"Average_Bytes\", avg(\"Bytes in the reply\").over(window_spec))\n",
        ")\n",
        "\n",
        "# Calculate the percentage of entries above the average for each HTTP method\n",
        "percentage_above_avg_df = (\n",
        "    avg_bytes_df\n",
        "    .withColumn(\n",
        "        \"Above_Avg_Percentage\",\n",
        "        sum(when(col(\"Bytes in the reply\") > col(\"Average_Bytes\"), 1).otherwise(0)).over(window_spec) / count(\"*\").over(window_spec)\n",
        "    )\n",
        "    .select(\"HTTP Method\",\n",
        "            \"Bytes in the reply\",\n",
        "            \"Average_Bytes\",\n",
        "            \"Above_Avg_Percentage\")\n",
        ")\n",
        "\n",
        "# Show the result\n",
        "percentage_above_avg_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "VIoGPCdD8jOJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}